\chapter{Conclusion}
\label{sec:conclusion}

PARDISO and other state-of-the-art sparse direct solvers utilize various techniques to improve performance. First, a reordering of the matrix is found. A~graph partitioning algorithm, called nested dissection, produces a reordering that minimizes fill-in and provides a high level of concurrency in factorization. Then, the matrix is factorized using $LU$, $LDL^T$, or $LL^T$ algorithm. Last, the solution is obtained by forward and backward substitution. In this thesis we focus on the last step, the forward and backward substitution. Certain applications require solving many times the same linear system $A$ with different right-hand sides, and thus the forward and backward substitution is essential for performance of these applications. Such applications are, for example, FETI domain decomposition methods or certain optimization problems.

The Berkeley roofline model is widely used to visualize the performance of executed code together with the upper performance bounds given by the memory bandwidth and the processor peak performance. The model can hereby provide an insightful visualization of bottlenecks. In this thesis a modification of the roofline model that allows us to cover combination of serial and parallel execution is introduced. This modified form of the roofline model is then applied to the triangular solve step of PARDISO. The performance of the forward and backward substitution process has been analyzed and benchmarked for a representative set of sparse matrices on various modern x86-type multicore architectures and the Knights Landing manycore architecture. It has been shown how to also accurately measure the necessary quantities, such as the achievable memory bandwidth, for threaded code. The measurement approach, its validation, as well as limitations were discussed.
Besides the Berkeley roofline model we also used the Erlangen ECM model. This model additionally accounts for in-cache traffic and the complete in-core execution. This advanced model delivers excellent predictions for vectorized code. However, modeling scalar code execution, as it is used in sparse triangular solve, is still under development. For the scalar code of sparse triangular solve we got a reasonable upper and lower bound of performance, but we did not achieve such good predictions as for the vectorized codes.

In the current factorization algorithm, the serial fraction of the factor $L$
increases with the number of cores. As a result, the highest performance for the sparse triangular solve phase is, typically, reached with four or eight cores.
PARDISO's high performance sparse triangular solve favors hardware with a high
memory bandwidth that can ideally be saturated with one or two cores.

The work presented in this thesis could be extended in several ways. One possible direction is to focus on the ECM model to improve performance predictions of sequential triangular solve and then apply it on the parallel code.
One could also focus on the performance modeling of other kernels in linear solvers. The best candidate here is the sparse factorization algorithm, as this is the kernel with the longest execution time.
Another direction is to focus on the extended roofline model presented in this thesis and use it for other applications that combine sequential and parallel execution.
