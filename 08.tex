\chapter{Conclusion}
\label{sec:conclusion}

PARDISO and other state-of-the-art sparse direct solvers utilize various techniques to improve performance. First, a reordering of the matrix is found. Graph partitioning algorithm called nested disection produce a reordering that minimizes fill-in and provide a high level of concurrency in factorization. Then the matrix is factorized using $LU$, $LDL^T$ or $LL^T$ algorithm. Last, the solution is obtained by forward and backward substitution. In this thesis we focus on the last step, the forward and backward substitution. Certain applications require solving many times the same system $A$ with different right hand sides, and thus the forward and backward substitution is essential for performance of these applications. Such appliations are, for example, FETI domain decomposition methods or optimization problems.

The Roofline model is widely used to visualize the performance of executed code together with the upper performance bounds given by the memory bandwidth and the processor peak performance. The model can hereby provide an insightful visualization of bottlenecks. In this thesis we applied the Berkeley Roofline model, in a modified form, to the sparse triangular solve step of PARDISO, a leading sparse direct solver package. The performance of the forward and backward substitution process has been analyzed and benchmarked for a representative set of sparse matrices on various modern x86-type multicore architectures and the Knights Landing manycore architecture. It has been shown how to accurately measure the necessary quantities also for threaded code, and the measurement approach, its validation, as well as limitations were discussed. Furthermore, a modified version of the Roofline model has been introduced covering the serial and parallel execution phases allowing for precise in-socket performance predictions.

In this thesis, PARDISO's sparse triangular solve algorithm has been analyzed regarding data transfers and floating point operations. This serves as input for our modified Roofline performance model. The model covers the serial and parallel execution phases of the forward and backward substitution and in general captures the behavior of the measured
performance. For Intel Ivy Bridge and Haswell (desktop) systems as well as AMD Zen platforms the model error is only up to $20$\,\%. However, for Intel Haswell (server), Broadwell, and Skylake (server) the model error raises up to $60$\,\% depending on the system and matrix. The observed deviations require a deeper analysis
of the architectures and the algorithm. Here, the ECM performance
model may be a suitable tool. This model additionally accounts for in-cache traffic and the complete in-core execution. This advanced model delivers excellent predictions for vectorized code. However, modeling scalar code execution, as it is used in sparse triangular solve, is still under development. For Knights Landing initial deviations of the model
of up to $130$\,\% result from the bottleneck given by the L2 bandwidth.
By adjustments, the error can be reduced, however with multiple cores the situation becomes more complex as L2 or memory bandwidth can be bottlenecks. Sparse triangular solve uses only scalar loads and stores, but with one core of the evaluated AMD Zen systems, it achieves nearly the same bandwidth as obtained with the vectorized read-only benchmark. In the current factorization algorithm the serial fraction of the factor $L$
increases with the number of cores. As a result, typically the highest performance for the sparse triangular solve phase is already reached with four or eight cores.
PARDISO's high performance sparse triangular solve favors hardware with a high
memory bandwidth that can ideally be saturated with one or two cores.
